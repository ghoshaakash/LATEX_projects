\documentclass[a4paper, 11pt]{book}
\usepackage{comment} % enables the use of multi-line comments (\ifx \fi) 
\usepackage{lipsum} %This package just generates Lorem Ipsum filler text. 
\usepackage[a4paper, total={7in, 10in}]{geometry}
\usepackage{amsmath}
\usepackage{amssymb,amsthm}  % assumes amsmath package installed
\newtheorem{theorem}{Theorem}
\newtheorem{corollary}{Corollary}
\usepackage{graphicx}
\usepackage{tikz}
\usetikzlibrary{arrows}
\usepackage{verbatim}
\usepackage[numbered]{mcode}
\usepackage{float}
\usepackage{tikz}
    \usetikzlibrary{shapes,arrows}
    \usetikzlibrary{arrows,calc,positioning}

    \tikzset{
        block/.style = {draw, rectangle,
            minimum height=1cm,
            minimum width=1.5cm},
        input/.style = {coordinate,node distance=1cm},
        output/.style = {coordinate,node distance=4cm},
        arrow/.style={draw, -latex,node distance=2cm},
        pinstyle/.style = {pin edge={latex-, black,node distance=2cm}},
        sum/.style = {draw, circle, node distance=1cm},
    }
\usepackage{xcolor}
\usepackage{mdframed}
\usepackage[shortlabels]{enumitem}
\usepackage{indentfirst}
\usepackage{hyperref}
\usepackage{mhchem}
\renewcommand{\thesubsection}{\thesection.\alph{subsection}}

\newenvironment{problem}[2][Problem]
    { \begin{mdframed}[backgroundcolor=blue!20] \textbf{#1 #2} \\}
    {  \end{mdframed}}

% Define solution environment
\newenvironment{solution}
    {\textit{Solution:}}
    {}

\newtheorem{lemma}{\textbf{Lemma}}

\setlength\parindent{0pt}
\renewcommand{\qed}{\quad\qedsymbol}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}\noindent
\textbf{Aakash Ghosh\hfill Probability-II\\
19MS129\hfill Assignment-1\\}



\begin{problem}{3}
    Let $\left\{X_{n}\right\}$ be a sequence of identically distributed random variables and let\\ $M_{n}=\max \left\{\left|X_{1}\right|,\left|X_{2}\right|, \hdots,\left|X_{n}\right|\right\}$.

    (a) If $\mathbb{E}\left[\left|X_{1}\right|\right]<\infty$, then show that $M_{n} / n$ converges to zero almost surely.

    (b) Generalization of part (a): If $\mathbb{E}\left[\left|X_{1}\right|^{\alpha}\right]<\infty$ for some $\alpha \in(0, \infty)$, then show that $M_{n} / n^{1 / \alpha}$ converges to zero almost surely.
    
    (c) Show that if the sequence $\left\{X_{n}\right\}$ is also independent, then $M_{n} / n^{1 / \alpha}$ converges to zero almost surely implies that $\mathbb{E}\left[\left|X_{1}\right|^{\alpha}\right]<\infty$.
    
    $\left[\operatorname{Hint}: M_{n} \geq\left|X_{n}\right| \cdot\right]$    
\end{problem}
\begin{solution} We shall use the following lemma:
    \begin{lemma}
        If $a_n/n\to0$ then $\max_{1\leq i\leq n}a_i/n\to0$
    \end{lemma}
    \begin{proof}
        Take any $\epsilon>0$. There exists $N$ such that for $n>N$ $|an/N|<\epsilon$. Let $M=max_{1\leq i\leq n}a_i$. If $M\geq \sup_{n> N}a_n$ then $\max_{1\leq i\leq n}a_i/n\leq M/n$ and we are done. Else, there exists $N'$ such that for $n>N'$, $\max_{1\leq i\leq n}a_i=a_j$ where $j>N$. But then we have $\max_{1\leq i\leq n}a_i/n=a_j/n=\left(a_n/j\right)\left(j/n\right)\leq \epsilon\left(j/n\right)\leq\epsilon$. Therefore, we conclude that $\max_{1\leq i\leq n}a_i/n$ converges to $0$. 
    \end{proof}
(a) By problem 2(a)[Note that in 2a we don't need independence assumptions], $E\left[|X_1\right]< \infty\Rightarrow X_n/n\to 0$ almost surely. Consider the set:
$$\mathcal{X}=\left\{\omega|\frac{|X_n(\alpha)|}{n}\to 0\right\}$$
We know that $P(\mathcal{X})=1$. For $\alpha\in\mathcal{X}$, $X_n(\alpha)/n\to0$. We use the lemma above to conclude that $M_n(\alpha)/n\to0$. Therefore,
$\{\omega|M_n(\omega)/n\to0\}\subset \mathcal{X}$ and thus $P(M_n/n\to0)\geq P(|X_n|/n\to0)=1$ or $M_n\to0$ almost surely. 
    
(b) Note that:
$$\max\{|X_1|^\alpha,|X_2|^\alpha,|X_3|^\alpha...|X_n|^\alpha\}=M_n^\alpha$$
By (a) we conclude that $M_n^\alpha/n\to 0$ almost surely. Note $f(x)=x^{\frac{1}{\alpha}}$ is a continuous map. Therefore, by the continuous mapping theorem, $M_n/n^{1/\alpha}\to 0$ almost surely.

(c) If $M_n/n^{1/\alpha}\to 0$ almost surely, then by continuous mapping theorem $M_n^\alpha/m\to 0$ almost surely. As
$X_n^\alpha(\omega)>\epsilon n\Rightarrow M_n(\omega)^\alpha>\epsilon n$, $P(M_n^\alpha>\epsilon n)\geq P(|X_n|^\alpha>\epsilon n)$. Therefore, $\sum_{n=1}^\infty P\left(X_n/n^\alpha<\epsilon\right)\leq\sum_{n=1}^\infty P\left(M_n/n^\alpha<\epsilon\right)<\infty$, and so we can conclude 
\end{solution}







\noindent\rule{7in}{2.8pt}

\end{document}
 